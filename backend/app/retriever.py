# backend/app/retriever.py
# ------------------------------------------------------------
# ‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏Ç‡∏∂‡πâ‡∏ô: ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô pgvector ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏¢‡∏∑‡∏° connection,
# ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ metadata ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á, ‡πÄ‡∏û‡∏¥‡πà‡∏° domain/protocol boosting,
# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ limit/top_n ‡∏à‡∏≤‡∏Å env ‡πÑ‡∏î‡πâ, ‡∏•‡πá‡∏≠‡∏Å error ‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢
# ------------------------------------------------------------
import os
import json
import logging
from typing import List, Any

from pydantic import Field
from langchain_core.retrievers import BaseRetriever
from langchain_core.documents import Document

from pgvector.psycopg2 import register_vector
from flashrank import Ranker, RerankRequest


def _safe_load_json(val):
    """‡∏Ñ‡∏∑‡∏ô dict ‡πÄ‡∏™‡∏°‡∏≠ ‡πÅ‡∏°‡πâ metadata ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠ None"""
    if not val:
        return {}
    if isinstance(val, dict):
        return val
    try:
        return json.loads(val)
    except Exception:
        return {"_raw_meta": str(val)}


def _env_int(key: str, default: int) -> int:
    try:
        return int(os.getenv(key, str(default)))
    except Exception:
        return default


class PostgresVectorRetriever(BaseRetriever):
    """
    ‡∏î‡∏∂‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡∏ï‡∏≤‡∏£‡∏≤‡∏á documents (pgvector)
    - ‡πÉ‡∏ä‡πâ connection_pool (psycopg2.pool)
    - ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô register_vector(conn) ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Å‡πà‡∏≠‡∏ô query
    - ‡∏Ñ‡∏∑‡∏ô list[Document] ‡∏û‡∏£‡πâ‡∏≠‡∏° metadata['distance']
    """
    connection_pool: Any = Field(...)
    embedder: Any = Field(...)
    collection: str = Field(default="plcnext")
    limit: int = Field(default_factory=lambda: _env_int("RETRIEVE_LIMIT", 50))

    def _get_relevant_documents(self, query: str) -> List[Document]:
        # ‡∏ù‡∏±‡πà‡∏á embedder (SentenceTransformer) ‡∏Ñ‡∏∑‡∏ô numpy.ndarray / list ‡πÑ‡∏î‡πâ ‚Üí ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ï‡∏£‡∏á ‡πÜ
        query_vector = self.embedder.encode(query)

        conn = self.connection_pool.getconn()
        try:
            # ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô vector type ‡∏Å‡∏±‡∏ö connection ‡∏ô‡∏µ‡πâ
            register_vector(conn)
            with conn.cursor() as cur:
                cur.execute(
                    """
                    SELECT content, metadata, embedding <-> %s AS distance
                    FROM documents
                    WHERE collection = %s
                    ORDER BY embedding <-> %s
                    LIMIT %s
                    """,
                    (query_vector, self.collection, query_vector, self.limit),
                )
                rows = cur.fetchall()

            docs: List[Document] = []
            for content, metadata, distance in rows:
                meta = _safe_load_json(metadata)
                meta["distance"] = float(distance)
                docs.append(Document(page_content=content, metadata=meta))
            return docs

        except Exception as e:
            logging.error("üî• Error in PostgresVectorRetriever: %s", e, exc_info=True)
            return []
        finally:
            self.connection_pool.putconn(conn)


class EnhancedFlashrankRerankRetriever(BaseRetriever):
    """
    ‡∏Ç‡∏±‡πâ‡∏ô rerank (lexical+semantic) ‡∏î‡πâ‡∏ß‡∏¢ Flashrank ‡πÅ‡∏•‡πâ‡∏ß‡∏ö‡∏ß‡∏Å domain-boost
    - base_retriever: ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏´‡∏≤ candidates ‡∏Å‡πà‡∏≠‡∏ô
    - ranker: ms-marco-MiniLM-L-12-v2 (‡πÇ‡∏´‡∏•‡∏î/‡πÅ‡∏Ñ‡∏ä‡πÉ‡∏ô /app/models)
    - top_n: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ (env: RERANK_TOPN)
    """
    base_retriever: BaseRetriever = Field(...)
    ranker: Ranker = Field(
        default_factory=lambda: Ranker(
            model_name="ms-marco-MiniLM-L-12-v2", cache_dir="/app/models"
        )
    )
    top_n: int = Field(default_factory=lambda: _env_int("RERANK_TOPN", 8))

    # ---- ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏Ñ‡∏∑‡∏≠ heuristic ‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏á‡πà‡∏≤‡∏¢ ----
    _PLC_TERMS = [
        "plcnext", "phoenix contact", "gds", "esm", "profinet", "axc f",
        "axc f 2152", "axc f 3152", "axc f 1152", "plcnext engineer"
    ]
    _PROTO_TERMS = [
        "protocol", "mode", "rs-485", "rs485", "profinet", "ethernet",
        "serial", "communication", "modbus", "tcp", "udp", "interface",
        "opcuA", "opc ua"
    ]

    def _calculate_domain_boost(self, doc: Document, query: str) -> float:
        txt = (doc.page_content or "").lower()
        q_tokens = (query or "").lower().split()

        boost = 0.0

        # 1) keyword ‡∏à‡∏≤‡∏Å PLCnext domain
        plc_hits = sum(1 for t in self._PLC_TERMS if t in txt)
        boost += plc_hits * 0.10  # 0.1 ‡∏ï‡πà‡∏≠‡∏Ñ‡∏≥

        # 2) ‡∏°‡∏µ token ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏ú‡∏•‡πà‡πÉ‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if any(tok in txt for tok in q_tokens if tok and len(tok) > 2):
            boost += 0.30

        # 3) protocol/mode ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö‡∏™‡∏≤‡∏¢‡∏≠‡∏∏‡∏ï‡∏™‡∏≤‡∏´‡∏Å‡∏£‡∏£‡∏°
        proto_hits = sum(1 for t in self._PROTO_TERMS if t in txt)
        if proto_hits > 0:
            boost += proto_hits * 0.50  # ‡πÉ‡∏´‡πâ‡∏´‡∏ô‡∏±‡∏Å‡∏´‡∏ô‡πà‡∏≠‡∏¢

        # 4) ‡πÉ‡∏´‡πâ golden/spec ‡∏û‡∏¥‡πÄ‡∏®‡∏©
        ctype = (doc.metadata or {}).get("chunk_type")
        if ctype == "golden_qa":
            boost += 10.0
        elif ctype == "spec_pair":
            boost += 0.20

        return boost

    def _get_relevant_documents(self, query: str) -> List[Document]:
        try:
            candidates = self.base_retriever.get_relevant_documents(query)
            if not candidates:
                return []

            passages = [
                {"id": i, "text": d.page_content, "meta": d.metadata}
                for i, d in enumerate(candidates)
            ]
            rr = RerankRequest(query=query, passages=passages)
            reranked = self.ranker.rerank(rr)

            scored = []
            for r in reranked:
                d = candidates[r["id"]]
                final_score = float(r["score"]) + self._calculate_domain_boost(d, query)
                scored.append({"doc": d, "score": final_score})

            scored.sort(key=lambda x: x["score"], reverse=True)
            return [x["doc"] for x in scored[: self.top_n]]

        except Exception as e:
            logging.error("üî• Error in EnhancedFlashrankRerankRetriever: %s", e, exc_info=True)
            return []
